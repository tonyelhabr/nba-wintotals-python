{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Created by: Anthony ElHabr\n",
    "# Purpose: Extract NBA teams from espn.go.com\n",
    "# Modified from: http://danielfrg.com/blog/2013/04/01/nba-scraping-data/\n",
    "# Only need to run this script once\n",
    "\n",
    "# import requests\n",
    "from urllib2 import urlopen\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, date\n",
    "\n",
    "YEAR = 2015\n",
    "teams_df = pd.read_csv(\"nba-teams.csv\", index_col=False)\n",
    "url_template = \"http://espn.go.com/nba/team/schedule/_/name/{0}/year/{1}/{2}\"\n",
    "\n",
    "# teams_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "game_id = []\n",
    "game_date = []\n",
    "team_schedule = []\n",
    "win_flag = []\n",
    "wins_to_date = []\n",
    "losses_to_date = []\n",
    "home_flag = []\n",
    "home_team = []\n",
    "home_score = []\n",
    "away_team = []\n",
    "away_score = []\n",
    "\n",
    "for index, row in teams_df.iterrows():\n",
    "    team_abbrv = row['team_abbrv']\n",
    "\n",
    "    # r =request.get(url_template.formatrow['team_abbrv'].lower(),\\\n",
    "    #                          YEAR, row['team_url_name'])\n",
    "    # schedule_table = BeautifulSoup(r.text).table\n",
    "    url = url_template.format(row['team_abbrv'].lower(),\\\n",
    "                              YEAR, row['team_url_name'])\n",
    "    html = urlopen(url)\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    schedule_table = soup.table\n",
    "\n",
    "    # ignore class=\"stathead\" row\n",
    "    for row in schedule_table.find_all('tr')[1:]:\n",
    "        columns = row.find_all('td')\n",
    "        \n",
    "        # try/except block will skip class=\"colhead\" rows\n",
    "        # and only parse class=\"oddrow...\" and class=\"evenrow...\" rows\n",
    "        try:\n",
    "            game_id.append(columns[2].a['href'].split('?id=')[1])\n",
    "            \n",
    "            d = datetime.strptime(columns[0].text, '%a, %b %d')\n",
    "            if d.month > 7:\n",
    "                d = date(YEAR-1, d.month, d.day)\n",
    "            else:\n",
    "                d = date(YEAR, d.month, d.day)\n",
    "            d = d.strftime('%m/%d/%Y')\n",
    "            game_date.append(d)\n",
    "            \n",
    "            team_schedule.append(team_abbrv)\n",
    "\n",
    "            win_boolean = True if columns[2].span.text == 'W' else False\n",
    "            win_flag.append('1' if win_boolean else '0')\n",
    "            \n",
    "            win_loss_record = columns[3].text.split('-')\n",
    "            wins_to_date.append(win_loss_record[0])\n",
    "            losses_to_date.append(win_loss_record[1])\n",
    "            \n",
    "            home_boolean = True if columns[1].li.text == 'vs' else False\n",
    "            home_flag.append('1' if home_boolean else '0')\n",
    "            \n",
    "            # text == '@' if team is away_team\n",
    "            other_team_name = columns[1].find_all('a')[1].text\n",
    "            other_team_abbrv = columns[1].find_all('a')[1]\\\n",
    "            ['href'].split('/')[-2]\n",
    "            home_team_abbrv = team_abbrv if home_boolean else other_team_abbrv\n",
    "            home_team_abbrv = home_team_abbrv.upper()\n",
    "            home_team.append(home_team_abbrv)\n",
    "            away_team_abbrv = team_abbrv if not home_boolean else other_team_abbrv\n",
    "            away_team_abbrv = away_team_abbrv.upper()\n",
    "            away_team.append(away_team_abbrv)\n",
    "            \n",
    "            # split(' ') is to ignore possible 'OT' label\n",
    "            both_scores = columns[2].a.text.split(' ')[0].split('-')\n",
    "            if home_boolean:\n",
    "                if win_boolean:\n",
    "                    home_score.append(both_scores[0])\n",
    "                    away_score.append(both_scores[1])\n",
    "                else:\n",
    "                    home_score.append(both_scores[1])\n",
    "                    away_score.append(both_scores[0])\n",
    "            else:\n",
    "                if win_boolean:\n",
    "                    home_score.append(both_scores[1])\n",
    "                    away_score.append(both_scores[0])\n",
    "                else:\n",
    "                    home_score.append(both_scores[0])\n",
    "                    away_score.append(both_scores[1])\n",
    "        except Exception as e:\n",
    "            pass\n",
    "            # print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "games_db_list = []\n",
    "set_of_lists = [game_id, game_date, team_schedule, win_flag,\\\n",
    "                wins_to_date, losses_to_date, home_flag,\\\n",
    "                home_team, away_team, home_score, away_score]\n",
    "\n",
    "for i in range(len(game_id)):\n",
    "    single_item = []\n",
    "    \n",
    "    for j in set_of_lists:\n",
    "        single_item.append(j[i])\n",
    "    \n",
    "    games_db_list.append(single_item)\n",
    "\n",
    "# games_db_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_col_headers = ['game_id', 'game_date', 'team_schedule', 'win_flag',\\\n",
    "                  'wins_to_date', 'losses_to_date', 'home_flag',\\\n",
    "                  'home_team', 'away_team', 'home_score', 'away_score']\n",
    "scores_2015_df = pd.DataFrame(games_db_list, columns=df_col_headers)\n",
    "\n",
    "# scores_2015_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# NOTE: dict does produce df in same order because it uses hashing to reorganize\n",
    "# the data that it is given\n",
    "games_dict = {'game_id': game_id,\\\n",
    "              'game_date': game_date,\\\n",
    "              'home_team': home_team,\\\n",
    "              'away_team': away_team,\\\n",
    "              'home_team_score': home_team_score,\\\n",
    "              'away_team_score': away_team_score}\n",
    "\n",
    "# print len(game_id), len(game_date), len(home_team), len(away_team),\\\n",
    "# len(home_team_score), len(away_team_score)\n",
    "\n",
    "games_df = pd.DataFrame(games_dict).drop_duplicates(subset='game_id').\\\n",
    "set_index('game_id')\n",
    "\n",
    "# games_df.head\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Need to delete file before creating new one\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# scores_2015_df.to_csv('nba-scores-2015.csv', index=False)\n",
    "if not os.path.isfile('nba-scores-2015.csv'):\n",
    "    scores_2015_df.to_csv('nba-scores-2015.csv', index=False)\n",
    "    print \"Creating new file\"\n",
    "else:\n",
    "    print \"Need to delete file before creating new one\"\n",
    "    # print \"Overwriting existing file\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
